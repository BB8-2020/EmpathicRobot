{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create validation set\n",
    "\n",
    "In this document we will take all photo's in a folder and put them through our photo_find_faces function. It will also put all the results in a DataFrame. And finally, it will turn this DataFrame into a json file.\n",
    "\n",
    "To make this code work, you have to download our validation photo set from our OneDrive. The foldername is 'first_Sanbot_validation_photos' or 'second_validation_set_sanbot'. Download it manually to your PC and insert the pixtures in the 'models/validation_model/data' folder under 'EmpathicRobot'. Check the link to the download page of the author [here](https://hogeschoolutrecht-my.sharepoint.com/:f:/g/personal/maria_dukmak_student_hu_nl/EmKTHJJBXwVDhK_mZs92P_QBwGA9g4wiIA_u6XJ0QhX55g?e=3bbP8u) with the password 'Toegang'. \n",
    "\n",
    "If you don't want to label data, you can download a already made validation_set.json file from the OneDrive.\n",
    "\n",
    "We need to get to the right directory in order for us to import the right functions. Set the path to where you saved the 'EmpathicRobot' project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# You need to change this path to your project path.\n",
    "os.chdir(\"/Users/Charlie/Desktop/School/Jaar_2/BB8/EmpathicRobot\")\n",
    "\n",
    "import validation_set\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparartion\n",
    "For our preparation we want to create a dataframe, this will be the beginning of the validation set. To get the right photo's we first need to go to the correct directory. Put the path to the data folder in the string below. Then we can go and get the file with all the photo's we want to use for our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.getcwd() + \"/models/validation_model/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Photo', 'Correct_emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main\n",
    "Now we are going to loop through our validation photo's. The user will be shown a photo and will be asked to write down which emotion he thinks this person depicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir():\n",
    "    row = df.append(validation_set.photo_find_faces(filename), ignore_index=True)\n",
    "    df = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn to json\n",
    "To finish our validationset, we first need to remove all the rows without any values. These rows were created by photo's where no face was detected. And finally we need to store our dataframe in a json file so it can be used by other programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('validation_set.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
